---
title: "III. Modeling Process Quality"
output: html_notebook
---


# 1. Describing Variability

## Stem-and-Leaf Plot
  - One of the most useful graphica techniques for summarizing and presenting data.

### Process
  - Assuming each data consists of at least two digits.
  - divide each number into two parts:
      - stem, consisting of one or more of the leading digits
      - leaf, consisting of the remaining digits
  - choose relatively few stems in comparison with the number of observations (between 5 and 20 stems)
  - list the chosen stems along the left-hand margin of the display
  - list beside each stem all leaves corresponding to the observed data values according to the order in which they are encountered in the data set.
```{r stem_and_leaf_plot}
days <- c(48,41,35,36,37,26,36,46,35,47,35,34,36,42,43,36,56,32,46,30,37,43,17,26,28,27,45,33,22,27,16,22,33,30,24,23,22,30,31,17)
stem(days)
```
## Time Series Plot (Run Chart)
- A plot of data values versus time.
- Called a marginal plot if a histogram/dot plot is attached to the margin of the chart.

```{r time_series_plot_marginal_plot}
###################################
# First Attempt, ggExtra approach
###################################
library(ggplot2)
library(ggExtra)
library(grid)
times <- c(1:40)
df <- data.frame(times, days)
p <- ggplot(df,aes(times,days))+ geom_point() +theme_classic()
mp <- ggMarginal(p,type="histogram",margins="y")
grid.newpage()
grid.draw(mp)

##################################################
# Second Attemp, Layout approach--preferable way
##################################################
new_layout <- layout(matrix(c(1,2),nrow=1,ncol=2),widths=c(5,1),heights=c(5,5),TRUE)
par(mar=c(5,4,2,0))
plot(df,xlab="Times",ylab="Days",main="Marginal Plot")
par(mar=c(5,0,2,1))
stripchart(days,method="stack",offset=0.5,vertical=TRUE,axes=FALSE)
```
## Histogram
  - is a more compact summary of data than a stem-and-leaf plot.
  - better suited for larger data set, 75 to 100 or more observations

### Process
  - Divide the range of the data into intervals-- **class intervals, cells, ** or **bins** _(determine upper and lower boundary of each bin)_
      - the number of bins depends on the number of observations and the amount of scatter or dispersion in the data. In general, between 5 to 20 bins is statisfactory in most cases.
      - Number of bins should increase with $n$, number of observations
      - approximately equal to the square root of the number observations often works well.
      - **Sturger's rule**, $h=1+\log_2n$ where $n$ is the sample size.
  - determine axes of the histogram 
      - Use horizontal axis to represent the measurement scale for the data
      - Use the vertical scale to represent the counts, or **frequencies**
      - when the frequencies in each bin are divided by the total number of observations $(n)$, it is called **relative frequencies**
  - draw rectangles over each bin so that the height of each rectangle is proportional to the frequenciy, or relative frequency
```{r histogram}  
thick <- c(438,413,444,468,445,472,474,454,455,449,450,450,450,459,466,470,457,441,450,445,487,430,446,450,456,433,455,459,423,455,451,437,444,453,434,454,448,435,432,441,452,465,466,473,471,464,478,446,459,464,441,444,458,454,437,443,465,435,444,457,444,471,471,458,459,449,462,460,445,437,461,453,452,438,445,435,454,428,454,434,432,431,455,447,454,435,425,449,449,452,471,458,445,463,423,451,440,442,441,439)
hist(thick)

defect <- c(6,1,5,7,8,6,0,2,4,2,5,2,4,4,1,4,1,7,2,3,4,3,3,3,6,3,2,3,4,5,5,2,3,4,4,4,2,3,5,7,5,4,5,5,4,5,3,3,3,12)
hist(defect,12)
```
## Numerical Summary of Data
 - Numerical measures of central tendency and scatter.
 - suppose that $x_1, x_2, ...,x_n$ are observations

### Sample Average
$$\bar{x}=\frac{x_1+x_2+...+x_n}{n}=\frac{\sum_{i=1}^{n}x_i}{n}$$
- arithmetic mean of the $n$ observations
```{r mean_calculation}
mean(thick)
```

### Sample Variance
$$s^2=\frac{\sum_{i=1}^{n}(x_i-\bar{x})^2}{n-1}$$
- measure variability in the sample data
- if there is no variability in the sample, each observation $x_i=\bar{x}$ and the sample variance $S^2=0$
```{r variance_calculation}
var(thick)
```
### Sample Standard Deviation
$$s=\sqrt{\frac{\sum_{i=1}^n(x_i-\bar{x})^2}{n-1}}$$
```{r standard_deviation}
sd(thick)

```
## Box Plot (Box Whisker Plot)
- graphical display for data that simultaneously displays:
      - central tendency
      - spread of variability
      - departure from symmetry
      - identification of outliers
- displays the three quartiles (Q1, Q2, and Q3), the minimum, and the maximum of the data on a rectangle box (vertical or horizontal)

```{r box_plot}
diameter <- c(120.5,120.9,120.3,121.3,120.4,120.2,120.1,120.5,120.7,121.1,120.9,120.8)
bp <- boxplot(diameter, horizontal=TRUE, xlab="Hole Diameters (mm)", border=TRUE, frame=FALSE,axes=FALSE)
leg <- as.character(bp$stats)
text(x=bp$stats,y=0.7,labels=leg)
```

## Probablity Distribution
- A mathematical model that relates the value of the variable with the probability of occurence that value in the population.
- There are two types of probability distribution:

### Continous Distributions
- when the variable being measured is on a continous scale, its probability distribution is called a _continous distribution_
- the appearance of the continous distribution is a curve with area under the curve equal to probability
- the probability that $x$ lies in the interval from $a$ to $b$ is written as 
$$P\{a\le{x}\le{b}\}=\int_a^b f(x)dx$$

### Discrete Distributions
- when the parameter being measured can only take on certain values, its probability distribution is called a _discrete distribution_
- the appearance of a discrete distribution is a series of vertical spikes with the height of each spike proportional to the probability.
- the distribution can be described as:
$$P\{x=x_i\}=p(x_i)$$

#### Central Tendency
- The *mean* $\mu$ of a probability distribution is a measure of the **central tendency** in the distribution.
- the mean is defined as
$$
\begin{equation}
\mu =
\begin{cases}
\int_{-\infty}^{\infty}xf(x)dx,x \text{ continuous}\\
\sum_{i=1}^{\infty}x_i p(x_i),x \text{ discrete}
\end{cases}
\end{equation}
$$
- the mean of a discrete random variable with exactly $N$ equally likely values can be simplified to

$$ \mu=\frac{\sum_{i=1}^{N}x_i}{N}$$

- the scatter, spread, or variability in a distribution is expressed by the **variance** $\sigma^2$
- the variance is defined as:

$$
\begin{equation}
\sigma^2=
\begin{cases}
\int_{-\infty}^{\infty}(x-\mu)^2f(x)dx,x \text{ continuous}\\
\sum_{i=1}^{\infty}(x_i-\mu)^2p(x_i),x \text{ discrete}
\end{cases}
\end{equation}
$$

- the variance of $N$ random variables with equally likely values becomes

$$
\sigma^2=\frac{\sum_{i=1}^{N}(x_i-\mu)^2}{N}
$$

- It is customary to work with square root of variance, called the **standard deviation** $\sigma$
$$
\sqrt{\sigma^2}=\sqrt{\frac{\sum_{i=1}^{N}(x_i-\mu)^2}{N}}
$$

- standard deviation is the measure of spread in the population 

# 2. Important Discrete Distributions

## The Hypergeometric Distribution

### Definition
- hypergeometric random variable $x$

    - within a finite population consisting of $N$ items, 
    
    - $D(D\le N)$ all into a class of interes
    
    - a random sample of $n$ items is selected from the population _without replacement_, $x$ is the number observed that belongs to the class of interst

#### probability distribution is defined as:

$$
p(x)=\frac{
\left(
\begin{matrix}
D\\
x
\end{matrix}
\right)
\left(
\begin{matrix}
N-D\\
n-x
\end{matrix}
\right)
}
{
\left(
\begin{matrix}
N\\
n
\end{matrix}
\right)
} 
x=0,1,2,...,\text{min}(n,D)
$$
- $D$: number of defective items in the population
- $x$: number of defective items in the sample
- $N$: number of items in the population
- $n$: number of items being sampled without replacement

#### Mean

$$
\mu=\frac{nD}{N}
$$
#### Variance

$$
\sigma^2=\frac{nD}{N}(1-\frac{D}{N})
(\frac{N-n}{N-1}) 
$$
#### Number of **Combinations of $a$ Items Taken $b$ at a Time** 

$$
\left(
\begin{matrix}
a\\
b
\end{matrix}
\right)=\frac{a!}{b!(a-b)!}
$$
- the **hypergeometric distribution** is the appropriate probability model for selecting a _random sample_ of $n$ items _without replacement_ from a lot of $N$ items of which $D$ are non conforming (defective)
- $x$ usually represents the number of nonconforming items found in the sample
```{r cumulative_distribution_of_hypergeomtric_distribution}
# Displaying Cumulative Distribution Function of Hypergeometric Distribution
# x=0,1,2,3,4,5,6,7,8,9,10
# D=5; nonconforming
# lot size, N =5+95=100, conforming=100-5=95
# n=10; sampling size
# p(X $\le$ x)
library(gridExtra)
library(grid)
drawn <- c(0:10)
cumulative.probability <- phyper(drawn,5,95,10)
# probability of 0, 1, 2, 3,...,10 nonconformative items found in the sample.
hyper <- cbind(drawn,cumulative.probability)
grid.newpage()
g <- grid.table(hyper)

```

## The Binomial Distribution

### Bernoulli Trials

- a process consists of a sequence of $n$ independent trials (the outcome of each trial does not depend in any way of the outcome of previous trials)
- the outcome of each trial is either a _success_ or a _failure_

### Definition

- the probability of "success" on any trial, $p$ is constant

- the number of "successes" $x$ in $n$ Bernoulli trial has the **bionomial distribution** with parameters $n \ge 0$ and $0<p<1$ defined as:

$$p(x)=\left(\begin{array} \\n \\x\end{array}\right)p^x(1-p)^{n-x}  \hspace{1cm} x=0,1,...,n$$

- The mean of the binomial distribution is
$$ \mu=np$$

- The variance of the binomial distribution is 

$$ \sigma^2=np(1-p)$$
- the binomial distribution is the appropriate probability model for sampling from an infinitely large population where

$p$ represents the fraction of defective item in poplulation
$x$ represents the number of nonconforming item found in a random sample of $n$ items
    
```{r binomial_distribution}
library(grid)
library(gridExtra)
drawn=c(0:10)
pd <- dbinom(drawn,15,0.1)
bd <- cbind(drawn,pd)
grid.newpage()
grid.table(bd)
```
- for a fixed $n$, the binomial distribution becomes more symmetric as $p$ increases from $0$ to $0.5$ or decreases from $1$ to $0.5$

- for a fixed $p$, the distriubtion becomes more symmetric as $n$ increases
```{r Binomial Distribution n_15 different p}
n=c(0:15)
bd0.1 <- dbinom(n,15,0.1)
bd0.5 <- dbinom(n,15,0.5)
bd0.9 <- dbinom(n,15,0.9)
barplot(bd0.1,n,col="blue",xlab="x",ylab="f(x)",beside=TRUE,axes=TRUE,width=15,space=1)
barplot(bd0.5,n,col="red",xlab="x",ylab="f(x)",beside=TRUE,axes=TRUE,width=15,space=1)
barplot(bd0.9,n,col="yellow",xlab="x",ylab="f(x)",beside=TRUE,axes=TRUE,width=15,space=1)
```
```{r binomialdistribution of different n fixed p}

n <- c(0:30)
bd1 <- dbinom(n,10,0.25)
bd2 <- dbinom(n,20,0.25)
bd3 <- dbinom(n,40,0.25)
barplot(bd1,n,col="blue",xlab="x",ylab="f(x)",beside=TRUE,axes=TRUE,width=15,space=1)
barplot(bd2,n,col="red",xlab="x",ylab="f(x)",beside=TRUE,axes=TRUE,width=15,space=1)
barplot(bd3,n,col="yellow",xlab="x",ylab="f(x)",beside=TRUE,axes=TRUE,width=15,space=1)
```
## The Poisson Distribution

## The Pascal and Related Distributions

# 3. Important Continuous Distributions

## The Normal Distribution

## The Lognormal Distribution

## The Exponential Distribution

## The Gamma Distribution

## The Weibull Distribution

# 4. Probability Plots

## Normal Probability Plot

## Other Probability Plots

# 5. Some Useful Approximation

## The Binomial Approximation to the Hypergeometric

## The Poisson Approximation to the Binomial

## The Normal Approximation to the Binomial

